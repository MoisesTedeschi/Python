{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reconhecimento de texto em imagens com Python e Tesseract OCR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MoisesTedeschi/Python/blob/master/Reconhecimento_de_texto_em_imagens_com_Python_e_Tesseract_OCR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmesFMpuh-WJ",
        "colab_type": "text"
      },
      "source": [
        "# **Transcrição de imagem em texto com Python e Tesseract OCR**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIfdO6wSfM6o",
        "colab_type": "text"
      },
      "source": [
        "![](https://uploaddeimagens.com.br/images/002/816/223/full/download.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrbUlyxyiNtG",
        "colab_type": "text"
      },
      "source": [
        "Nós, os seres humanos, podemos entender o conteúdo de uma imagem simplesmente olhando para ela. Percebemos o conteúdo de imagem e, automaticamente, sabemos se é possível ler o texto. Ou seja, é uma capacidade quase que involuntária – Olhar, ver a imagem, ler o texto (separando o que é texto e/ou figuras) e processar o conteúdo. Contudo, os computadores não funcionam da mesma maneira. Eles precisam de algo mais “concreto” e organizado de uma maneira que possam entender o conteúdo de uma imagem digital.\n",
        "\n",
        "Mas o que é uma imagem um computador?\n",
        "\n",
        "Segundo Gonzalez, R. and Woods, R. (1992), uma imagem pode ser definida como uma função f(x, y), onde o valor nas coordenadas espaciais x e y corresponde ao brilho (intensidade) da imagem nessa coordenada.\n",
        "\n",
        "A única forma de se representar uma imagem em um computador é quando ela está digitalizada tanto no domínio espacial como no das amplitudes. \n",
        "\n",
        "Uma imagem digital é a representação numérica e discreta de um objeto, ou especificamente, é uma função quantificada e amostrada, de duas dimensões, geradas por meios ópticos, disposta em um grade padrão, retangular igualmente espaçada, quantificada em iguais intervalos de amplitude. Assim, uma imagem digital é um vetor retangular bidimensional de amostras de valores quantificados (Cordeiro (2002), Castleman (1996)).\n",
        "\n",
        "Em outras palavras, uma imagem digital é (basicamente) um conjunto de três canais de cor. Também conhecidos como [***RGB***](https://pt.wikipedia.org/wiki/RGB) (RED – GREEN – BLUE). O RGB pode variar seus valores internos entre 0 e 255. Assim, a “mistura” dos elementos gera uma imagem digital. Vale lembrar que, as menores unidades de uma imagem digital são denominadas Picture Element (Pixel). Um pixel é a representação numérica da luminosidade de um ponto da imagem.\n",
        "\n",
        "Bem, agora sabemos o que é uma imagem digital, não é mesmo?!\n",
        "\n",
        "É nesse momento que entra o ***OCR*** - *“Optical Character Recognition”* (Tradução Livre: Reconhecimento Óptico de Caracteres). Na prática, essa tecnologia faz a leitura de um arquivo em imagem para identificar padrões e/ou transcrever textos que estão contidos em placas, publicidade, livros e/ou documentos manuscritos que devem ser convertidos em cópia digital. Embora nem sempre seja perfeito, é muito conveniente e torna muito mais fácil e rápido para algumas pessoas realizarem seu trabalho.\n",
        "\n",
        "# **Aplicação na vida real**\n",
        "\n",
        "Um exemplo muito comum de aplicação do OCR, mas que, ao mesmo tempo causa enorme dor de cabeça para condutores, são os radares de trânsito. Eles possuem câmeras de alta sensibilidade que captura uma foto da placa do carro que está irregular e envia para um sistema que utilizará o OCR para extrair os números e letras da imagem que foi recebida."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPQ4YIvgf7GO",
        "colab_type": "text"
      },
      "source": [
        "![](https://media1.tenor.com/images/d7b8afdded86064c3d946a3dc3950d70/tenor.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86XWmH9ijD6J",
        "colab_type": "text"
      },
      "source": [
        "Neste texto, para ilustrar o a funcionalidade das aplicações OCR, irei demonstrar o reconhecimento óptico de caracteres usando o ***Tesseract OCR***."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9VjCrCJjRZB",
        "colab_type": "text"
      },
      "source": [
        "Originalmente, o Tesseract foi desenvolvido na Hewlett-Packard Laboratories Bristol e na Hewlett-Packard Co, Greeley Colorado (1985 à 1994). Depois de algumas mudanças, foi portado para Windows em 1996, além de alguns upgrades em 1998. Contudo, só em 2005 o Tesseract foi liberado para a comunidade pela HP. Assim, desde 2006 é desenvolvido/mantido pela [***Google***](https://opensource.google/projects/tesseract).\n",
        "\n",
        "Texto original em: https://github.com/tesseract-ocr/tesseract\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KGwprKSjusx",
        "colab_type": "text"
      },
      "source": [
        "# **O que usaremos?**\n",
        "\n",
        "Para este projeto de OCR, precisamos do Tesseract OCR. O processo de instalação se encontra no link: https://github.com/tesseract-ocr/tesseract/wiki\n",
        "\n",
        "Instalações no Windows, o executável pode ser baixado no link: https://github.com/UB-Mannheim/tesseract/wiki\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSQIJZ6QgC81",
        "colab_type": "text"
      },
      "source": [
        "![](https://uploaddeimagens.com.br/images/002/816/225/full/downloadOCR.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyX8YTE1kPBZ",
        "colab_type": "text"
      },
      "source": [
        "É muito importante incluir na instalação o suporte à linguagem “portuguese”.\n",
        "\n",
        "Usaremos, também, a biblioteca ***Python Tesseract***, ou simplesmente ***PyTesseract***, que é um “cápsula” (invólucro) do mecanismo Tesseract-OCR do Google. Como o código é aberto, a escolha é bem óbvia. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzytuEFugc22",
        "colab_type": "text"
      },
      "source": [
        "![](https://uploaddeimagens.com.br/images/002/816/226/full/download2.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvOG8pmNktRb",
        "colab_type": "text"
      },
      "source": [
        "Também usaremos o virtualenv, pois ele lida com a configuração do ambiente virtual. Ou seja, vamos isolar nossa aplicação em um ambiente virtual dedicado ao projeto. Em caso de dúvidas, como o foco dessa aplicação não é entrar em detalhes sobre o ambiente virtual, recomendo o post: https://pythonacademy.com.br/blog/python-e-virtualenv-como-programar-em-ambientes-virtuais\n",
        "\n",
        "A biblioteca [***Pillow***](https://pypi.org/project/Pillow/), que é um *“fork”* (bifurcação) da PIL (Python Imaging Library) para lidar com a abertura e manipulação de imagens em muitos formatos no Python, também, será utilizada.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1Q_4c1-ghvZ",
        "colab_type": "text"
      },
      "source": [
        "![](https://uploaddeimagens.com.br/images/002/816/230/original/show.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RA0P71MalGax",
        "colab_type": "text"
      },
      "source": [
        "# **Show Me!!!**\n",
        "\n",
        "Para esta aplicação OCR simples, vou utilizar o PyCharm (questão de gosto mesmo). Com seu diretório selecionado, crie um arquivo ***.py*** e vamos chamar de extraindo-texto-de-imagem.py (você escolhe o nome que desejar). No mesmo diretório que o arquivo ***.py*** coloque uma imagem. No meu caso, vou usar a imagem abaixo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5AAS4qZg0jx",
        "colab_type": "text"
      },
      "source": [
        "![](https://uploaddeimagens.com.br/images/002/816/233/full/basedeuso.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47kyjyiklaEZ",
        "colab_type": "text"
      },
      "source": [
        "No seu terminal (ou CMD no Windows), você pode criar um ambiente virtual e começar a importação das bibliotecas. Como, no momento, estou usando uma versão do Windows, o código pode ser um pouquinho diferente. Assim sendo, recomendo o link acima sobre os [*ambientes virtuais*](https://pythonacademy.com.br/blog/python-e-virtualenv-como-programar-em-ambientes-virtuais).\n",
        "\n",
        "**Implementação**\n",
        "\n",
        "Com a instalação concluída e bibliotecas instaladas, agora podemos criar uma função simples que obtém uma imagem e retorna o texto detectado na imagem - este será o núcleo do nosso projeto:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5lFp-tSiSOw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "cfbd9658-9e25-45bb-a5c7-2b8cfe3c6da6"
      },
      "source": [
        "# A instalação do tesseract aqui foi necessária para rodar a aplicação no\n",
        "# Google Colaboratory.\n",
        "!sudo apt install tesseract-ocr"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 4,795 kB of archives.\n",
            "After this operation, 15.8 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-eng all 4.00~git24-0e00fe6-1.2 [1,588 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-osd all 4.00~git24-0e00fe6-1.2 [2,989 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr amd64 4.00~git2288-10f4998a-2 [218 kB]\n",
            "Fetched 4,795 kB in 2s (3,056 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 144487 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.00~git2288-10f4998a-2_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Setting up tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "363Mhbrcl_jk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "506ae285-e1b0-473e-f89c-732b4fa43bf7"
      },
      "source": [
        "# Instalação de bibliotecas no Google Colaboratory.\n",
        "!pip install Pillow\n",
        "!pip install pytesseract"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (7.0.0)\n",
            "Collecting pytesseract\n",
            "  Downloading https://files.pythonhosted.org/packages/1d/d8/521db389ff0aae32035bfda6ed39cb2c2e28521c47015f6431f07460c50a/pytesseract-0.3.4.tar.gz\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from pytesseract) (7.0.0)\n",
            "Building wheels for collected packages: pytesseract\n",
            "  Building wheel for pytesseract (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytesseract: filename=pytesseract-0.3.4-py2.py3-none-any.whl size=13431 sha256=dd5d5b16453e9703e9611d0604978825a1161b4c464ed66fb5d797c2afb8c420\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/2a/a0/7596d2e0a73cf0aeffd6f6170862c4e73f3763b7827e48691a\n",
            "Successfully built pytesseract\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldY26daQiVah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importando as bibliotecas instaladas.\n",
        "from PIL import Image\n",
        "import pytesseract"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S10c54-OwoE5",
        "colab_type": "text"
      },
      "source": [
        "Nós importamos *“Image”* da biblioteca **Pillow** e da nossa biblioteca **PyTesseract**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXhKg5zQiTfB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Indicando caminho.\n",
        "pytesseract.pytesseract.tesseract_cmd = (\n",
        "    r'/usr/bin/tesseract'\n",
        ")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOAJ6rT5wxMo",
        "colab_type": "text"
      },
      "source": [
        "Foi necessário indicar o caminho para o Google Colaboratory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iONntAmkiXHZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "70a88588-e691-4103-8f3f-8a86853b78e9"
      },
      "source": [
        "# Apenas verificando se está tudo \"OK\".\n",
        "pytesseract.image_to_string"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function pytesseract.pytesseract.image_to_string>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COA-N8lWicZF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCa8liBsiY7_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def img_core_file(imgfile):\n",
        "    \"\"\"\n",
        "    A função manipulará o processamento principal de imagens OCR.\n",
        "    \"\"\"\n",
        "    text_extracao = pytesseract.image_to_string(Image.open(imgfile))\n",
        "\n",
        "    # Usaremos a classe Image do Pillow para abrir a imagem e\n",
        "    # o pytesseract para detectar a string na imagem\n",
        "    # É muito IMPORTANTE que o valor “lang” esteja em português, pq o valor\n",
        "    # padrão é inglês. Logo, afeta no resultado de saída do texto.\n",
        "\n",
        "    return text_extracao"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CmlAUPbxNqT",
        "colab_type": "text"
      },
      "source": [
        "Em seguida, criamos uma função *“img_core_file”* que recebe um nome de arquivo e retorna o texto contido na imagem. \n",
        "\n",
        "***Image.open()*** recebe uma string indicando um caminho válido de uma imagem (quando não especificado o diretório, a busca ocorrerá na raiz do seu arquivo de script) e retorna uma referência a um objeto em memória do tipo **PIL.Image**.\n",
        "\n",
        "***Pytesseract.image_to_string()*** recebe o parâmetro obrigatório *“image”*, e o opcional *“lang”*, isto informa ao tesseract que o alfabeto que ele está tentando reconhecer é o português (suportando acentos e cedilha), caso não especificado seu padrão é ‘*eng’*, inglês.\n",
        "\n",
        "Atribuído o retorno do texto reconhecido para a variável *“text_extracao”*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uC2q1XESiaix",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "c5d0f7f1-1e3c-474a-a10f-d55b9a1ebe41"
      },
      "source": [
        "# Não esquecer de adicionar a imagem no drive - Se tiver usando o Google\n",
        "# Colaboratory.\n",
        "\n",
        "print(img_core_file('vaidarcerto.jpeg'))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nao se deixe vencer pelos\n",
            "obstaculos; vocé pode estar\n",
            "prestes a abrir a porta certa\n",
            "\n",
            "e nunca sabera se nao\n",
            "continuar tentando.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsr5xpIEnM3r",
        "colab_type": "text"
      },
      "source": [
        "Assim, o valor é extraído é o retorno da função. Com isso, na última linha estamos invocando um *print()*, chamando a função dentro dele e passando a imagem que desejamos extrair o texto.\n",
        "\n",
        "Ao executarmos obtemos o texto que estava na imagem e ele é editável:\n",
        "\n",
        "***“Não se deixe vencer pelos obstáculos; você pode estar prestes a abrir a porta certa e nunca saberá se não continuar tentando.”***\n",
        "\n",
        "Trecho de código, somos recebidos com isso:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRJMYYWmhHJj",
        "colab_type": "text"
      },
      "source": [
        "![](https://uploaddeimagens.com.br/images/002/816/236/original/OUTPUT.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vruwec73vVUY",
        "colab_type": "text"
      },
      "source": [
        "# **Dessa vez com um texto em Inglês**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E17hphCghWLY",
        "colab_type": "text"
      },
      "source": [
        "![](https://uploaddeimagens.com.br/images/002/816/237/full/NOVAIMAGEM.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRadEN5WN0Kv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6260c9c2-193c-4b51-b379-6bcda16a9476"
      },
      "source": [
        "# Não esquecer de adicionar a imagem no drive - Se tiver usando o Google\n",
        "# Colaboratory.\n",
        "\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "print(pytesseract.image_to_string(Image.open('python-assert.png')))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ASSERT STATEMENTS\n",
            "IN PYTHON\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xg6HejLvhk4T",
        "colab_type": "text"
      },
      "source": [
        "![](https://media.giphy.com/media/12NUbkX6p4xOO4/giphy.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDQ7pnb5Ckpf",
        "colab_type": "text"
      },
      "source": [
        "# **Os problems... São os problems**\n",
        "\n",
        "Como o Tesseract não é \"bala de prata\" (não resolve tudo e em todos os casos) é evidência de que o OCR nem sempre é 100%. Logo, é necessário/preciso de intervenção humana de tempos em tempos.\n",
        "\n",
        "Existe de possíveis problemas nesta [***wiki***](https://github.com/tesseract-ocr/tesseract/wiki/ImproveQuality). Várias etapas podem ser feitas para melhorar a fidelidade da ***Engine***, tais como: \n",
        "\n",
        "Redimensionamento, binarização, redução de ruídos, rotação/alinhamento das linhas e remoção das bordas. Nos casos mais simples, a resolução pode ser via retirada de bordas descartando a parte excedente do texto antes enviar ao pytesseract.\n",
        "\n",
        "Segundo o *wiki* acima, uma imagem elegível para uma extração mais fiel pelo tesseract-OCR deve possuir as seguintes recomendações:\n",
        "<br />\n",
        "<br />\n",
        "\n",
        "* Dois canais de cores somente (preto e branco). Seja ela em escala de cinza (0≤ Vi≤ 255) ou então a imagem binarizada (Vi== 0 || Vi== 255). Vi=Valor de intensidade.\n",
        "<br />\n",
        "<br />\n",
        "* Texto alinhado/padronizado e sem ruídos (gerados geralmente durante a etapa de binarização).\n",
        "<br />\n",
        "<br />\n",
        "* Altura do box (espaço ocupado pelos caracteres) superior ao mínimo de 10px.\n",
        "Densidade ideal de 300dpi, ou proporcionais para o pressuposto acima.\n",
        "Possuir o texto extraível em um único padrão de alfabeto (ou idioma).\n",
        "Sem espaço inútil, considerado como bordas para o texto.\n",
        "\n",
        "<br />\n",
        "<br />\n",
        "\n",
        "**Still having problems?**\n",
        "\n",
        "Se você tentou, mas ainda está obtendo resultados de baixa precisão, peça ajuda no [***fórum***](https://groups.google.com/forum/?fromgroups#!forum/tesseract-ocr), postando sua imagem que deseja extrair conteúdo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWGY2vkioL0A",
        "colab_type": "text"
      },
      "source": [
        "# **Por fim...**\n",
        "\n",
        "Nesta aplicação, nós nos concentramos na biblioteca **PyTesseract**. Contudo, existem outras *Libs* Python que podem ajudar na extração de textos de imagens. Por exemplo:\n",
        "\n",
        "[***Textract***](https://pypi.org/project/textract/): Pode extrair dados de PDF’s.\n",
        "\n",
        "[***Pyocr***](https://gitlab.gnome.org/World/OpenPaperwork/pyocr): Oferece mais opções de detecção, como frases, dígitos ou palavras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hk6sxbKVon1L",
        "colab_type": "text"
      },
      "source": [
        "# **Autores Citados**\n",
        "\n",
        "* Gonzalez and Woods (1992) GONZALES, R. C. WOODS, R. E. Digital Image Processing. University of Tennessee Perceptics Corporation, 1992.\n",
        "\n",
        "* Cordeiro (2002) Cordeiro, F. M. Reconhecimento e Classificação de Padrões de Imagens de Núcleos Linfócitos do Sangue Periférico Humano coma Utilização de Redes Neurais Artificiais. Universidade Federal deSanta Catarina, 2002.\n",
        "\n",
        "* Castleman (1996) Castleman, Kenneth R. Digital Image Processing. Upper Saddler River: Prentice Hall, Inc. 1996."
      ]
    }
  ]
}