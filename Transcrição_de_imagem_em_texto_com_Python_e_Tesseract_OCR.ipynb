{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transcrição de imagem em texto com Python e Tesseract OCR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MoisesTedeschi/Python/blob/master/Transcri%C3%A7%C3%A3o_de_imagem_em_texto_com_Python_e_Tesseract_OCR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmesFMpuh-WJ",
        "colab_type": "text"
      },
      "source": [
        "# **Transcrição de imagem em texto com Python e Tesseract OCR**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIfdO6wSfM6o",
        "colab_type": "text"
      },
      "source": [
        "![](https://uploaddeimagens.com.br/images/002/816/223/full/download.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrbUlyxyiNtG",
        "colab_type": "text"
      },
      "source": [
        "Nós, os seres humanos, podemos entender o conteúdo de uma imagem simplesmente olhando para ela. Percebemos o conteúdo de imagem e, automaticamente, sabemos se é possível ler o texto. Ou seja, é uma capacidade quase que involuntária – Olhar, ver a imagem, ler o texto (separando o que é texto e/ou figuras) e processar o conteúdo. Contudo, os computadores não funcionam da mesma maneira. Eles precisam de algo mais “concreto” e organizado de uma maneira que possam entender o conteúdo de uma imagem digital.\n",
        "\n",
        "Mas o que é uma imagem para um computador?\n",
        "\n",
        "Segundo Gonzalez, R. and Woods, R. (1992), uma imagem pode ser definida como uma função f(x, y), onde o valor nas coordenadas espaciais x e y corresponde ao brilho (intensidade) da imagem nessa coordenada.\n",
        "\n",
        "A única forma de se representar uma imagem em um computador é quando ela está digitalizada tanto no domínio espacial como no das amplitudes. \n",
        "\n",
        "Uma imagem digital é a representação numérica e discreta de um objeto, ou especificamente, é uma função quantificada e amostrada, de duas dimensões, geradas por meios ópticos, disposta em um grade padrão, retangular igualmente espaçada, quantificada em iguais intervalos de amplitude. Assim, uma imagem digital é um vetor retangular bidimensional de amostras de valores quantificados (Cordeiro (2002), Castleman (1996)).\n",
        "\n",
        "Em outras palavras, uma imagem digital é (basicamente) um conjunto de três canais de cor. Também conhecidos como [***RGB***](https://pt.wikipedia.org/wiki/RGB) (RED – GREEN – BLUE). O RGB pode variar seus valores internos entre 0 e 255. Logo, a “mistura” dos elementos gera uma imagem digital. Vale lembrar que, as menores unidades de uma imagem digital são denominadas Picture Element (Pixel). Um pixel é a representação numérica da luminosidade de um ponto da imagem.\n",
        "\n",
        "Bem, agora sabemos o que é uma imagem digital (ou não). É nesse momento que entra o motivo de escrever e o OCR - “Optical Character Recognition” (Tradução Livre: Reconhecimento Óptico de Caracteres). \n",
        "\n",
        "O motivo principal (além da curiosidade):  Considere a preguiça como fator chave da evolução humana, okey?! Então... Quando o ser humano é motivado pela espírito da automação de algo, na real, o combustível é a preguiça. O ato fazer sempre a mesma coisa por um longo período de tempo é, literalmente, um saco. Agora imagine ter que redigitar documentos longos burocráticos por um longo período de tempo, imaginou?! É, você entendeu a motivação. Enfim, mas e a tecnologia? \n",
        "\n",
        "Na prática, essa tecnologia (OCR) faz a leitura de um arquivo em imagem para identificar padrões e/ou transcrever textos que estão contidos em placas, publicidade, livros e/ou documentos manuscritos que devem ser convertidos em cópia digital. Embora nem sempre seja perfeito, é muito conveniente e torna muito mais fácil e rápido para algumas pessoas realizarem seu trabalho. (\"Uhm... Interessante, não é mesmo?!\")\n",
        "\n",
        "# **Mas e a aplicação na vida real?**\n",
        "\n",
        "Um exemplo muito comum de aplicação do OCR, mas que, ao mesmo tempo causa enorme dor de cabeça para os condutores, são os radares de trânsito. Eles possuem câmeras de alta sensibilidade que capturam fotos da placa dos veículos (em casos irregulares) e enviam os arquivos para um sistema que utilizará o OCR para extrair os números e letras da imagem que foi recebida."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPQ4YIvgf7GO",
        "colab_type": "text"
      },
      "source": [
        "![](https://media1.tenor.com/images/d7b8afdded86064c3d946a3dc3950d70/tenor.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86XWmH9ijD6J",
        "colab_type": "text"
      },
      "source": [
        "No texto, para ilustrar o funcionamento do OCR, irei demonstrar o reconhecimento óptico de caracteres usando o ***Tesseract OCR***."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9VjCrCJjRZB",
        "colab_type": "text"
      },
      "source": [
        "Originalmente, o Tesseract foi desenvolvido na Hewlett-Packard Laboratories Bristol e na Hewlett-Packard Co, Greeley Colorado (1985 à 1994). Depois de algumas mudanças, foi portado para Windows em 1996, além de alguns upgrades em 1998. Contudo, só em 2005 o Tesseract foi liberado para a comunidade pela HP. Assim sendo, desde 2006 é desenvolvido/mantido pela [***Google***](https://opensource.google/projects/tesseract).\n",
        "\n",
        "Repositório no GitHub: https://github.com/tesseract-ocr/tesseract\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KGwprKSjusx",
        "colab_type": "text"
      },
      "source": [
        "# **Início dos trabalhos com Tesseract OCR**\n",
        "\n",
        "Para o exemplo de OCR, precisamos do Tesseract OCR. O processo de instalação se encontra no link: https://github.com/tesseract-ocr/tesseract/wiki\n",
        "\n",
        "Para instalações no Windows, o executável pode ser baixado no link: https://github.com/UB-Mannheim/tesseract/wiki\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSQIJZ6QgC81",
        "colab_type": "text"
      },
      "source": [
        "![](https://uploaddeimagens.com.br/images/002/816/225/full/downloadOCR.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyX8YTE1kPBZ",
        "colab_type": "text"
      },
      "source": [
        "* É muito importante incluir na instalação o suporte à linguagem “portuguese”.\n",
        "\n",
        "O funcionamento do exemplo depende, também, da **Lib** *(biblioteca)* do **Tesseract** para a linguagem Python ***(PyTesseract)***, que é uma \"cápsula\" (invólucro) do mecanismo Tesseract-OCR do Google.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzytuEFugc22",
        "colab_type": "text"
      },
      "source": [
        "![](https://uploaddeimagens.com.br/images/002/816/226/full/download2.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvOG8pmNktRb",
        "colab_type": "text"
      },
      "source": [
        "Não vamos esquecer de criar um ambiente virtual *(virtualenv)*, é claro - Só questão de segurança para não corromper sua instalação principal do Python. Ou seja, vamos isolar nosso exemplo em um ambiente virtual. Em caso de dúvidas, recomendo o post: https://pythonacademy.com.br/blog/python-e-virtualenv-como-programar-em-ambientes-virtuais\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1Q_4c1-ghvZ",
        "colab_type": "text"
      },
      "source": [
        "![](https://uploaddeimagens.com.br/images/002/816/230/original/show.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RA0P71MalGax",
        "colab_type": "text"
      },
      "source": [
        "# **Show Me!!!**\n",
        "\n",
        "Para o simples script Python com OCR, a opção de uso de editor foi o [Google Colab](https://colab.research.google.com). Como usarei o Google Colab (mais fácil para rodar o exemplo), a instalação do tesseract será um pouco diferente do que citei acima. No \"Colab\" é necessário rodar o comando:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5lFp-tSiSOw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "outputId": "089cf19a-e865-4439-80d5-c71783a02c37"
      },
      "source": [
        "!sudo apt install tesseract-ocr"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 4,795 kB of archives.\n",
            "After this operation, 15.8 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-eng all 4.00~git24-0e00fe6-1.2 [1,588 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-osd all 4.00~git24-0e00fe6-1.2 [2,989 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr amd64 4.00~git2288-10f4998a-2 [218 kB]\n",
            "Fetched 4,795 kB in 1s (4,064 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 144487 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.00~git2288-10f4998a-2_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Setting up tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKNFxZkQ18Tt",
        "colab_type": "text"
      },
      "source": [
        "A biblioteca [***Pillow***](https://pypi.org/project/Pillow/), que é um *“fork”* (bifurcação) da PIL (Python Imaging Library) para lidar com a abertura e manipulação de imagens em muitos formatos no Python, também, será utilizada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "363Mhbrcl_jk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "9b866fcd-f64d-448f-cce1-bd5e26c01522"
      },
      "source": [
        "# Instalação de bibliotecas no Google Colaboratory.\n",
        "\n",
        "!pip install Pillow\n",
        "!pip install pytesseract"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (7.0.0)\n",
            "Collecting pytesseract\n",
            "  Downloading https://files.pythonhosted.org/packages/1d/d8/521db389ff0aae32035bfda6ed39cb2c2e28521c47015f6431f07460c50a/pytesseract-0.3.4.tar.gz\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from pytesseract) (7.0.0)\n",
            "Building wheels for collected packages: pytesseract\n",
            "  Building wheel for pytesseract (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytesseract: filename=pytesseract-0.3.4-py2.py3-none-any.whl size=13431 sha256=a93322c3d6f5ad3206fa50d8798a5e353e2fb9cc065089f514967166933b1ef1\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/2a/a0/7596d2e0a73cf0aeffd6f6170862c4e73f3763b7827e48691a\n",
            "Successfully built pytesseract\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pf-KrWBS26nZ",
        "colab_type": "text"
      },
      "source": [
        "Com a instalação do `tesseract-ocr` concluída e bibliotecas instaladas.\n",
        "\n",
        "Importamos as bibliotecas instaladas. `Image` da biblioteca Pillow e da nossa biblioteca PyTesseract."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldY26daQiVah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importando as bibliotecas instaladas.\n",
        "\n",
        "from PIL import Image\n",
        "import pytesseract"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5Al0_8V3UZ_",
        "colab_type": "text"
      },
      "source": [
        "* É necessário indicar o caminho do \"tesseract\" para o Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXhKg5zQiTfB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pytesseract.pytesseract.tesseract_cmd = (\n",
        "    r'/usr/bin/tesseract'\n",
        ")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CmlAUPbxNqT",
        "colab_type": "text"
      },
      "source": [
        "Agora podemos criar uma função que obtém uma imagem e retorna o texto detectado na imagem.\n",
        "\n",
        "`Image.open()` recebe uma string indicando um caminho válido de uma imagem (quando não especificado o diretório, a busca ocorrerá na raiz do seu arquivo de script) e retorna uma referência a um objeto em memória do tipo **PIL.Image**.\n",
        "\n",
        "`Pytesseract.image_to_string()` recebe o parâmetro obrigatório *“image”*, e o opcional *“lang”*, isto informa ao tesseract que o alfabeto que ele está tentando reconhecer é o português *(suportando acentos e cedilha)*, caso não especificado seu padrão é ‘*eng’*, inglês.\n",
        "\n",
        "Atribuído o retorno do texto reconhecido para a variável `text_extracao`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCa8liBsiY7_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def img_core_file(imgfile):\n",
        "    \"\"\"\n",
        "    A função manipulará o processamento principal de imagens OCR.\n",
        "\n",
        "     - Usaremos a classe Image do Pillow para abrir a imagem e\n",
        "     o pytesseract para detectar a string na imagem.\n",
        "\n",
        "     - É muito IMPORTANTE que o valor “lang” esteja em português, pq o valor\n",
        "     padrão é inglês (Idem a instalação. Lembra?). Logo, afeta no resultado de\n",
        "     saída do texto.\n",
        "    \"\"\"\n",
        "\n",
        "    text_extracao = pytesseract.image_to_string(Image.open(imgfile))\n",
        "\n",
        "    return text_extracao"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTxQWxUq6pHJ",
        "colab_type": "text"
      },
      "source": [
        "Imagem de exemplo:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5AAS4qZg0jx",
        "colab_type": "text"
      },
      "source": [
        "![](https://uploaddeimagens.com.br/images/002/816/233/full/basedeuso.jpeg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7SoboijDXQT",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "b73bb555-2586-4664-90f3-76673ee88fd7"
      },
      "source": [
        "# Código para fazer upload de arquivos no Google Colab. Logo, não funciona\n",
        "# no ambiente local (na sua máquina local).\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-326d8043-d204-4c3e-8d28-2822c3e638c4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-326d8043-d204-4c3e-8d28-2822c3e638c4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving vaidarcerto.jpeg to vaidarcerto.jpeg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgsHT0cG76ww",
        "colab_type": "text"
      },
      "source": [
        "Em seguida, criamos uma função `img_core_file` que recebe um nome de arquivo e retorna o texto contido na imagem. \n",
        "\n",
        "Com o valor extraído vem do retorno de uma função, estou invocação do `print`. Ou seja, chamando a função (`img_core_file`) dentro dele e passando a imagem que desejamos extrair o texto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uC2q1XESiaix",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "fab89be1-263d-42d2-f636-e6ade6057da2"
      },
      "source": [
        "# Não esquecer de adicionar a imagem no drive - Se tiver usando o Google\n",
        "# Colab.\n",
        "\n",
        "print(img_core_file('vaidarcerto.jpeg'))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nao se deixe vencer pelos\n",
            "obstaculos; vocé pode estar\n",
            "prestes a abrir a porta certa\n",
            "\n",
            "e nunca sabera se nao\n",
            "continuar tentando.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8vsjsBK_gnm",
        "colab_type": "text"
      },
      "source": [
        "##**Usando um ambiente local**\n",
        "\n",
        "No seu terminal (ou CMD no Windows), você pode criar um ambiente virtual e começar a importação das bibliotecas. Como, no momento, estou usando uma versão do Windows, o código pode ser um pouquinho diferente. Assim sendo, recomendo o link sobre os [*ambientes virtuais*](https://pythonacademy.com.br/blog/python-e-virtualenv-como-programar-em-ambientes-virtuais).\n",
        "\n",
        "\n",
        "**Processo no ambiente local é parecido com o do Google Colab:**\n",
        "\n",
        "Com a instalação concluída (*Idem a instalação do Tesseract OCR acima.)* e bibliotecas do Python instaladas, você cria a função (`img_core_file`) que obtém a imagem e retorna o texto detectado na imagem.\n",
        "\n",
        "Na IDE PyCharm - Com seu diretório selecionado, crie um arquivo ***.py*** e chame do que quiser, eu chamei o meu de ***extraindo-texto-de-imagem.py***. No mesmo diretório que o arquivo ***.py*** coloque uma imagem. Feito isso é só rodar o script e com o comando: `python extraindo-texto-de-imagem.py` e o resultado será:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRJMYYWmhHJj",
        "colab_type": "text"
      },
      "source": [
        "![](https://uploaddeimagens.com.br/images/002/816/236/original/OUTPUT.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vruwec73vVUY",
        "colab_type": "text"
      },
      "source": [
        "# **Mas imagens com texto em inglês, a extração funciona?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E17hphCghWLY",
        "colab_type": "text"
      },
      "source": [
        "![](https://uploaddeimagens.com.br/images/002/816/237/full/NOVAIMAGEM.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJe6ACqPEtsw",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "a28cadca-4a72-44ec-f76c-7c4af6820369"
      },
      "source": [
        "# Código para fazer upload de arquivos no Google Colab. Logo, não funciona\n",
        "# no ambiente local (na sua máquina local).\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-07c71584-5ca9-4a6d-be1e-293f74940c09\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-07c71584-5ca9-4a6d-be1e-293f74940c09\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving python-assert.png to python-assert.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhNPKmc3FynW",
        "colab_type": "text"
      },
      "source": [
        "Com a imagem em seu devido lugar, nós podemos passar o nome da imagem para a função e ela fará todo o trabalho de extração de texto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRadEN5WN0Kv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "69977dbd-8d76-4ee1-a3ed-969fd20b8a3b"
      },
      "source": [
        "print(pytesseract.image_to_string(Image.open('python-assert.png')))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ASSERT STATEMENTS\n",
            "IN PYTHON\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xg6HejLvhk4T",
        "colab_type": "text"
      },
      "source": [
        "![](https://media.giphy.com/media/12NUbkX6p4xOO4/giphy.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDQ7pnb5Ckpf",
        "colab_type": "text"
      },
      "source": [
        "# **Os problems... São os problems**\n",
        "\n",
        "Como o Tesseract não é \"bala de prata\" (não resolve tudo e nem vai) é evidência de que o OCR nem sempre é 100%. Logo, é necessário/preciso de intervenção humana de tempos em tempos.\n",
        "\n",
        "Existem de possíveis problemas listados no [***wiki***](https://github.com/tesseract-ocr/tesseract/wiki/ImproveQuality). Várias etapas podem ser feitas para melhorar a fidelidade da ***Engine***, tais como: \n",
        "\n",
        "Redimensionamento, binarização, redução de ruídos, rotação/alinhamento das linhas e remoção das bordas. Nos casos mais simples, a resolução pode ser via retirada de bordas descartando a parte excedente do texto antes enviar ao pytesseract - Claro que existem outras possibilidades e bibliotecas, é claro. Por exemplo, o uso do **OpenCV** (detalhes no [aqui](https://www.geeksforgeeks.org/text-detection-and-extraction-using-opencv-and-ocr/)), mas isso fica para outro papo.\n",
        "\n",
        "Segundo o *wiki* acima, uma imagem elegível para uma extração mais fiel pelo tesseract-OCR deve possuir as seguintes recomendações:\n",
        "<br />\n",
        "<br />\n",
        "\n",
        "* Dois canais de cores somente (preto e branco). Seja ela em escala de cinza (0≤ Vi≤ 255) ou então a imagem binarizada (Vi== 0 || Vi== 255). Vi=Valor de intensidade.\n",
        "<br />\n",
        "<br />\n",
        "* Texto alinhado/padronizado e sem ruídos (gerados geralmente durante a etapa de binarização).\n",
        "<br />\n",
        "<br />\n",
        "* Altura do box (espaço ocupado pelos caracteres) superior ao mínimo de 10px.\n",
        "Densidade ideal de 300dpi, ou proporcionais para o pressuposto acima.\n",
        "Possuir o texto extraível em um único padrão de alfabeto (ou idioma).\n",
        "Sem espaço inútil, considerado como bordas para o texto.\n",
        "\n",
        "<br />\n",
        "<br />\n",
        "\n",
        "**Still having problems?**\n",
        "\n",
        "Se você tentou, mas ainda está obtendo resultados de baixa precisão, peça ajuda no [***fórum***](https://groups.google.com/forum/?fromgroups#!forum/tesseract-ocr), postando sua imagem que deseja extrair conteúdo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWGY2vkioL0A",
        "colab_type": "text"
      },
      "source": [
        "# **Por fim...**\n",
        "\n",
        "No exemplo, nós nos concentramos na biblioteca **PyTesseract**. Contudo, existem outras *Libs* Python que podem ajudar na extração de textos de imagens. Por exemplo:\n",
        "\n",
        "[***OpenCV***](https://opencv-python-tutroals.readthedocs.io/en/latest/index.html): Pode extrair, também, textos de imagens, reconhecimento facial e afins.\n",
        "\n",
        "[***Textract***](https://pypi.org/project/textract/): Pode extrair dados de PDF’s.\n",
        "\n",
        "[***Pyocr***](https://gitlab.gnome.org/World/OpenPaperwork/pyocr): Oferece mais opções de detecção, como frases, dígitos ou palavras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hk6sxbKVon1L",
        "colab_type": "text"
      },
      "source": [
        "# **Autores Citados**\n",
        "\n",
        "* Gonzalez and Woods (1992) GONZALES, R. C. WOODS, R. E. Digital Image Processing. University of Tennessee Perceptics Corporation, 1992.\n",
        "\n",
        "* Cordeiro (2002) Cordeiro, F. M. Reconhecimento e Classificação de Padrões de Imagens de Núcleos Linfócitos do Sangue Periférico Humano coma Utilização de Redes Neurais Artificiais. Universidade Federal deSanta Catarina, 2002.\n",
        "\n",
        "* Castleman (1996) Castleman, Kenneth R. Digital Image Processing. Upper Saddler River: Prentice Hall, Inc. 1996."
      ]
    }
  ]
}